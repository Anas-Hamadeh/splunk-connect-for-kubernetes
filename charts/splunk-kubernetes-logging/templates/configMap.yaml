apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "splunk-kubernetes-logging.fullname" . }}
  labels:
    app: {{ template "splunk-kubernetes-logging.name" . }}
    chart: {{ template "splunk-kubernetes-logging.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  fluent.conf: |
    # system wide configurations
    <system>
      log_level {{ or .Values.logLevel .Values.global.logLevel | default "info" }}
    </system>

    # reading kubelet logs from journal
    <source>
      @type systemd
      tag journal.kubernetes.kubelet
      filters [{ "_SYSTEMD_UNIT": "kubelet.service" }]
      path  {{ .Values.journalLogPath | default "/run/log/journal" | quote }}
      read_from_head true
      <storage>
        @type local
        persistent true
        path fluentd-kubelet-journal.pos
      </storage>
      # rename the message key name to keep it consistent with container logs for easier formatting later in output.
      <entry>
        field_map {"MESSAGE": "log"}
        field_map_strict true
      </entry>
    </source>

    # reading kubernetes system components' logs from container
    <source>
      @type tail
      tag containers.kubernetes.components
      path "/var/log/containers/kube-*.log,
            /var/log/containers/dns-controller-*.log,
            /var/log/containers/etcd-*.log
            "
      pos_file /var/log/fluentd-containers.kubernetes.log.pos
      path_key _file_path
      read_from_head true
      <parse>
        @type json
        time_key time
        time_type string
        time_format "%Y-%m-%dT%H:%M:%S.%NZ"
        localtime false
      </parse>
    </source>

    # reading applications' logs (non-system pods' logs) from container
    <source>
      @type tail
      tag containers.applications
      path /var/log/containers/*.log
      exclude_path [
        "/var/log/containers/kube-*.log",
        "/var/log/containers/dns-controller-*.log",
        "/var/log/containers/etcd-*.log"
      ]
      pos_file /var/log/fluentd-containers.applications.log.pos
      path_key _file_path
      read_from_head true
      <parse>
        @type json
        time_key time
        time_type string
        time_format "%Y-%m-%dT%H:%M:%S.%NZ"
        localtime false
      </parse>
    </source>

    # ignore fluentd's log
    <match fluent.**>
      @type null
    </match>

    <match **>
      @type splunk_hec
      template_engine jq
      protocol {{ or .Values.splunk.hec.protocol .Values.global.splunk.hec.protocol | default "https" }}
      hec_host {{ required "splunk.hec.host is required." (or .Values.splunk.hec.host .Values.global.splunk.hec.host) }}
      hec_token "#{ENV['SPLUNK_HEC_TOKEN']}"
      host "#{ENV['SPLUNK_HEC_HOST']}"
      source '{% if (.tag | startswith("containers.")) then .record._file_path else .tag end %}'
      sourcetype '{% if (.tag | contains(".kubernetes.")) then "glog" else "access_combined" end %}'
      {{- if .Values.splunk.hec.indexName }}
      index {{ .Values.splunk.hec.indexName }}
      {{- end }}
      insecure_ssl {{ or .Values.splunk.hec.insecureSSL .Values.global.splunk.hec.insecureSSL | default false }}
      {{- with $clientCert := or .Values.splunk.hec.clientCert .Values.global.splunk.hec.clientCert }}
      {{ if $clientCert }}client_cert {{ $clientCert }}{{ end }}
      {{- end }}
      {{- with $clientKey := or .Values.splunk.hec.clientKey .Values.global.splunk.hec.clientKey }}
      {{ if $clientKey }}client_key {{ $clientKey }}{{ end }}
      {{- end }}
      {{- with $caFile := or .Values.splunk.hec.caFile .Values.global.splunk.hec.caFile }}
      {{ if $caFile }}ca_file {{ $caFile }}{{ end }}
      {{- end }}
      {{- with $caPath := or .Values.splunk.hec.caPath .Values.global.splunk.hec.caPath }}
      {{ if $caPath }}ca_path {{ $caPath }}{{ end }}
      {{- end }}
      <buffer>
        @type memory
        {{- $limit := .Values.resources.limit }}
        chunk_limit_size {{ if $limit.memory }}{{ template "splunk-kubernetes-logging.convert-memory" $limit.memory }}{{ else }}{{ "500m" }}{{ end }}
        chunk_limit_records 512000
        flush_interval 5s
        flush_thread_count 1
        overflow_action block
        retry_max_times 3
      </buffer>
      <format>
        # we just want to keep the raw logs, not the structure created by container or journal
        @type single_value
        message_key log
        add_newline false
      </format>
    </match>
